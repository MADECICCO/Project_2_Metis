{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define a movie class for practice with Python objects\n",
    "'''\n",
    "\n",
    "class movie:\n",
    "    def __init__(self, title, year, credits, rating):\n",
    "        movie.title = title\n",
    "        movie.year = year\n",
    "        movie.credits = credits\n",
    "        movie.rating = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Scrape movie info from IMDB, input is an IMDB movie number\n",
    "Returns a dictionary with movie information\n",
    "'''\n",
    "\n",
    "def scrape_movie(movie_num, debugging=False):\n",
    "    page_link = 'https://www.imdb.com/title/' + str(movie_num)\n",
    "    page_response = requests.get(page_link, timeout=1000)\n",
    "    page_content = BeautifulSoup(page_response.content, 'lxml')\n",
    "    \n",
    "    credits = page_content.find_all('div', class_='credit_summary_item')\n",
    "    \n",
    "    # Title and year\n",
    "    title_str = page_content.h1.text\n",
    "    for i, val in enumerate(title_str):\n",
    "        if val == '(':\n",
    "            split_index = i-1\n",
    "            break\n",
    "    movie_title = title_str[:split_index]\n",
    "    movie_year_raw = title_str[split_index:]\n",
    "    year = [i for i in movie_year_raw if i.isdigit()]\n",
    "    movie_year = int(''.join(year))\n",
    "    \n",
    "    # Runtime\n",
    "    try:\n",
    "        tech_link = 'https://www.imdb.com/title/' + str('tt2345759') + '/technical?ref_=tt_dt_spec'\n",
    "        tech_response = requests.get(tech_link, timeout=1000)\n",
    "        tech_content = BeautifulSoup(tech_response.content, 'lxml')\n",
    "        runtime = int(re.findall(r'\\(\\d+', tech_content.table.find_all('td')[1].text.strip())[0].replace('(',''))\n",
    "    except:\n",
    "        runtime = None\n",
    "    \n",
    "    # Parental Guidance\n",
    "    try:\n",
    "        parental_guidance = re.findall(r'^.+\\b', page_content.find_all('div', class_='subtext')[0].text.strip())\n",
    "    except:\n",
    "        parental_guidance = None\n",
    "    \n",
    "    # Credits\n",
    "    credits_dict = {}\n",
    "    for i in credits:\n",
    "        key = i.h4.text[:-1]\n",
    "        value = []\n",
    "        sub_credit = i.find_all('a')\n",
    "        for j in sub_credit:\n",
    "            value.append(j.text)\n",
    "        credits_dict[key] = value\n",
    "    \n",
    "    # Genre\n",
    "    index = len(page_content.find_all('div', class_='see-more inline canwrap')) - 1\n",
    "    genres = []\n",
    "    for i in page_content.find_all('div', class_='see-more inline canwrap')[index].text.split():\n",
    "        if (i != 'Genres:') and (i != '|'):\n",
    "            genres.append(i)\n",
    "    \n",
    "    # Rating\n",
    "    imdb_rating = None\n",
    "    if page_content.find_all('div', class_='ratingValue') != []:\n",
    "        imdb_rating = float(page_content.find_all('div', class_='ratingValue')[0].find('span').text)\n",
    "    \n",
    "    num_critics = 0\n",
    "    if page_content.find_all('div', class_='metacriticScore score_favorable titleReviewBarSubItem') != []:\n",
    "        meta_rating = page_content.find_all('div', class_='metacriticScore score_favorable titleReviewBarSubItem')\n",
    "        meta_rating = int(meta_rating[0].text)/10\n",
    "        num_critics_str = page_content.find('a', {'href': re.compile(r'^externalreviews.*')}).text\n",
    "        num_critics = int(''.join([i for i in num_critics_str if i.isdigit()]))\n",
    "    elif page_content.find_all('div', class_='metacriticScore score_mixed titleReviewBarSubItem') != []:\n",
    "        meta_rating = page_content.find_all('div', class_='metacriticScore score_mixed titleReviewBarSubItem')\n",
    "        meta_rating = int(meta_rating[0].text)/10\n",
    "        num_critics_str = page_content.find('a', {'href': re.compile(r'^externalreviews.*')}).text\n",
    "        num_critics = int(''.join([i for i in num_critics_str if i.isdigit()]))\n",
    "    elif page_content.find_all('div', class_='metacriticScore score_unfavorable titleReviewBarSubItem') != []:\n",
    "        meta_rating = page_content.find_all('div', class_='metacriticScore score_unfavorable titleReviewBarSubItem')\n",
    "        meta_rating = int(meta_rating[0].text)/10\n",
    "        num_critics_str = page_content.find('a', {'href': re.compile(r'^externalreviews.*')}).text\n",
    "        num_critics = int(''.join([i for i in num_critics_str if i.isdigit()]))\n",
    "    else:\n",
    "        meta_rating = None\n",
    "    \n",
    "    # Awards\n",
    "    try:\n",
    "        awards_str = page_content.find('span', {'class': re.compile(r'awards-blurb.*')}).text.strip()\n",
    "    except:\n",
    "        awards_str = None\n",
    "    \n",
    "    # Budget and USA Box Office\n",
    "    div_content = page_content.find_all('div', class_='txt-block')\n",
    "    \n",
    "    budget = None\n",
    "    usa_gross = None\n",
    "    release_month = None\n",
    "    country = None\n",
    "    for i, val in enumerate(div_content):\n",
    "        if val.h4 is not None:\n",
    "            if val.h4.text.find('Budget') >= 0:\n",
    "                budget_index = i\n",
    "                budget = int(''.join([i for i in div_content[budget_index].text.split()[0] if i.isdigit()]))\n",
    "            elif val.h4.text.find('Gross USA') >= 0:\n",
    "                gross_usa_index = i\n",
    "                usa_gross = int(''.join([i for i in div_content[gross_usa_index].text.split()[2] if i.isdigit()]))\n",
    "            elif val.h4.text.find('Release Date') >= 0:\n",
    "                release_index = i\n",
    "                release_month = div_content[release_index].text.split()[3]\n",
    "                country = div_content[release_index].text.split()[5]\n",
    "                country = country.replace('(','')\n",
    "                country = country.replace(')','')\n",
    "    \n",
    "    movie_dict = {}\n",
    "    movie_dict['title'] = movie_title\n",
    "    movie_dict['year'] = movie_year\n",
    "    movie_dict['release_month'] = release_month\n",
    "    movie_dict['imdb_num'] = movie_num\n",
    "    movie_dict['parental_guidance'] = parental_guidance\n",
    "    movie_dict['runtime'] = runtime\n",
    "    movie_dict['box_office_country'] = country\n",
    "    #movie_dict['credits'] = credits_dict\n",
    "    movie_dict['star'] = credits_dict['Stars'][0]\n",
    "    movie_dict['director'] = credits_dict['Director'][0]\n",
    "    movie_dict['genres'] = genres[0]\n",
    "    movie_dict['imdb_rating'] = imdb_rating\n",
    "    movie_dict['meta_rating'] = meta_rating\n",
    "    movie_dict['num_critics'] = num_critics\n",
    "    movie_dict['budget'] = budget\n",
    "    movie_dict['usa_gross'] = usa_gross\n",
    "    \n",
    "    if debugging:\n",
    "        return movie_dict, page_content, div_content, tech_content\n",
    "    else:\n",
    "        return movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor_movies(actor_num, debugging=False):\n",
    "    zero_str = ''\n",
    "    for i in range(7 - len(str(actor_num))):\n",
    "        zero_str += '0'\n",
    "    page_link = 'https://www.imdb.com/name/nm0000' + str(actor_num)\n",
    "    page_response = requests.get(page_link, timeout=1000)\n",
    "    page_content = BeautifulSoup(page_response.content, 'lxml')\n",
    "    filmography = page_content.find_all('div', {'class': re.compile(r'^.*\\b(filmo-row)\\b.*$'),\n",
    "                                                'id': re.compile(r'^.*\\b(actor|actress)\\b.*$')})\n",
    "\n",
    "    movies = []\n",
    "    movie_nums = []\n",
    "    for i in filmography:\n",
    "        if (i.text.find('TV Series')<0) and (i.text.find('pre-production')<0) and (i.text.find('post-production')<0):\n",
    "            movies.append(i.a.text)\n",
    "            movie_nums.append(i.a['href'].split('/')[2])\n",
    "\n",
    "    movie_dict_list = []\n",
    "    for i in movie_nums:\n",
    "        print(i)\n",
    "        try:\n",
    "            movie_dict = scrape_movie(i)\n",
    "            movie_dict_list.append(movie_dict)\n",
    "        except:\n",
    "            print('here')\n",
    "            continue\n",
    "            \n",
    "    if debugging:\n",
    "        return movie_dict_list, movies, movie_nums\n",
    "    else:\n",
    "        return movie_dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box office performance = intercept \n",
    "    # + B1*month_of_release + B2*weather + B3*meta_rating + B4*unemployment_rate \n",
    "    # + B5*genre + B6*budget + B7*is_sequel + B8*interaction_term(for whether previous was good)\n",
    "    # + B9*age_of_star + B10*rating_of_movie + B11*past_ROI_of_star + B12*past_critic_of_director\n",
    "    # + B13*decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([movie_dict_list[0]])\n",
    "\n",
    "actor_nums = [129, #Tom Cruise\n",
    "              210, #Julia Roberts\n",
    "              413168, #Hugh Jackman\n",
    "              1083271, #Megan Fox\n",
    "              158, #Tom Hanks\n",
    "              149, #Jodie Foster\n",
    "              216, #Ahhhhhnold\n",
    "              148, #Harrison Ford\n",
    "              246, #Bruce Willis\n",
    "              230, #Sly Stallone\n",
    "              4266, #Anne Hathaway\n",
    "              243, #Denzel Washington\n",
    "              424060, #Scarlett Johansson\n",
    "              138, #Leo DiCaprio\n",
    "              1401, #Angelina Jolie\n",
    "              237, #John Travolta\n",
    "              658, #Meryl Streep\n",
    "              212, #Meg Ryan\n",
    "              288, #Christian Bale\n",
    "              1191, #Adam Sandler\n",
    "              1706767, #Jonah Hill\n",
    "              226, #Will Smith\n",
    "              113, #Sandra Bullock\n",
    "              331516, #Ryan Gosling\n",
    "              425005, #The Rock\n",
    "              168, #Samuel L Jackson\n",
    "              199, #Al Pacino\n",
    "              151, #Morgan Freeman\n",
    "              553, #Liam Neeson\n",
    "              93, #Brad Pitt\n",
    "              123, #George Clooney\n",
    "              354, #Matt Damon\n",
    "              1567113, #Jessica Chastain\n",
    "              204, #Natalie Portman\n",
    "              1557, #Viggo Mortensen\n",
    "              120, #Jim Carrey\n",
    "              195, #Bill Murray\n",
    "              316079, #Paul Gia\n",
    "              190, #Matt Mcc\n",
    "              350453, #Jake G\n",
    "              332, #Don Cheadle\n",
    "              205626, #Viola Davis\n",
    "              156, #Jeff Goldblum\n",
    "              1475594, #Channing Tatum\n",
    "              194, #Julianne Moore\n",
    "              358, #Daniel Day Lewis\n",
    "              949, #Cate Blanchett\n",
    "              234, #Charlize Theron\n",
    "              173, #Nicole Kidman\n",
    "              2225369, #Jennifer Lawrence\n",
    "              163, #Dustin Hoffman\n",
    "              191, #Ewan McGregor\n",
    "              228, #Kevin Spacey\n",
    "              128, #Russell Crowe\n",
    "              564215, #James McAvoy\n",
    "              1297015, #Emma Stone\n",
    "              702, #Reese Witherspoon\n",
    "              179, #Jude Law\n",
    "              569, #G Paltrow\n",
    "              982, #Josh Brolin\n",
    "              182, #JLo\n",
    "              255, #Ben Affleck\n",
    "              5028, #Kate Hudson\n",
    "              177896, #Bradley Cooper\n",
    "              695435, #Chris Pratt\n",
    "              245, #Robin Williams\n",
    "              914612, #Emma Watson\n",
    "              136797, #Steve Carell\n",
    "              5562 #Owen Wilson\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_df = pd.DataFrame()\n",
    "for actor_num in actor_nums:\n",
    "    print('Now on Actor Number: ' + str(actor_num))\n",
    "    movie_dict_list = get_actor_movies(actor_num)\n",
    "    \n",
    "    for i in movie_dict_list:\n",
    "        movie_df = movie_df.append(i, ignore_index=True)\n",
    "        movie_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Pickle files\n",
    "\n",
    "# open a file, where you want to store the data\n",
    "# file = open('movie_df_additional', 'wb')\n",
    "# dump information to that file\n",
    "# pickle.dump(movie_df, file)\n",
    "# close the file\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickles\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('movie_df_to_148_HFord', 'rb')\n",
    "# dump information to that file\n",
    "df1 = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('movie_df_to_331516_RGosling', 'rb')\n",
    "# dump information to that file\n",
    "df2 = pickle.load(file)\n",
    "# close the file\n",
    "file.close()\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('movie_df_to_last', 'rb')\n",
    "# dump information to that file\n",
    "df3 = pickle.load(file)\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine into one dataframe\n",
    "\n",
    "final_df = pd.DataFrame()\n",
    "final_df = final_df.append(df1, ignore_index=True)\n",
    "final_df = final_df.append(df2, ignore_index=True)\n",
    "final_df = final_df.append(df3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop_duplicates(subset='imdb_num', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(labels='index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['genres'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Debugging\n",
    "movie_dict, page_content, div_content, tech_content = scrape_movie('tt2345759', debugging=True)\n",
    "movie_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
