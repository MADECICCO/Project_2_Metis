{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "from patsy import dmatrices, dmatrix\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from scipy.stats import poisson\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poisson exploration\n",
    "p_random = np.random.poisson(2, 10000)\n",
    "p_mean = np.mean(p_random)\n",
    "p_std = np.std(p_random)\n",
    "p_norm = [(i - p_mean)/p_std for i in p_random]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(p_random, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted(np.power(p_random, 1/2)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickles\n",
    "\n",
    "file = open('final_df_pickle_v1.0', 'rb')\n",
    "final_df = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('actor_bday_v1.0', 'rb')\n",
    "bday_dict = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more_bdays_df = pd.read_csv(\"name.basics.tsv\", sep=\"\\t\")\n",
    "\n",
    "# file = open('more_bdays_df', 'wb')\n",
    "# pickle.dump(more_bdays_df, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('more_bdays_df', 'rb')\n",
    "more_bdays_df = pickle.load(file)\n",
    "file.close()\n",
    "more_bdays_df = more_bdays_df[['primaryName','birthYear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bdays_df = more_bdays_df[more_bdays_df['primaryName'].isin(list(set(final_df['star'])))]\n",
    "master_bdays_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_bdays_df[master_bdays_df['primaryName']=='Tom Cruise'].iloc[0]['birthYear'].isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bday(star):\n",
    "    try:\n",
    "        counter = 0\n",
    "        while master_bdays_df[master_bdays_df['primaryName']==star].iloc[counter]['birthYear'].isnumeric() != True:\n",
    "            counter += 1\n",
    "        return master_bdays_df[master_bdays_df['primaryName']==star].iloc[counter]['birthYear']\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "final_df['birth_year'] = final_df['star'].apply(get_bday)\n",
    "print('Still missing bdays for ' + str(sum([1 for i in final_df['birth_year'].isna() if i])) + ' actors')\n",
    "missing_list = final_df[final_df['birth_year'].isna()]['star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(missing_list)))\n",
    "set(missing_list)\n",
    "\n",
    "# Drop stars with no birthdays\n",
    "final_df.dropna(inplace=True)\n",
    "print(final_df.shape)\n",
    "\n",
    "# Modify 'The Conversation' movie's release month (scrape error)\n",
    "final_df.loc[list(final_df[final_df['release_month']=='1974'].index)[0], 'release_month'] = 'June'\n",
    "\n",
    "final_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust datatypes\n",
    "to_numeric_cols = ['budget','imdb_rating','meta_rating','runtime','usa_gross']\n",
    "for i in to_numeric_cols:\n",
    "    final_df[i] = pd.DataFrame(final_df[i], dtype='float')\n",
    "final_df['year'] = pd.DataFrame(final_df['year'], dtype='int')\n",
    "final_df['birth_year'] = pd.DataFrame(final_df['birth_year'], dtype='int')\n",
    "\n",
    "# Add interesting columns\n",
    "\n",
    "final_df['profit'] = final_df['usa_gross'] - final_df['budget']\n",
    "final_df['log_usa_gross'] = np.log(list(final_df['usa_gross']))\n",
    "final_df['root_usa_gross'] = np.power(list(final_df['usa_gross']), 1/3)\n",
    "final_df['log_budget'] = np.log(list(final_df['budget']))\n",
    "final_df['root_budget'] = np.power(list(final_df['budget']), 1/3)\n",
    "final_df['one_over_budget'] = 1/(final_df['budget'])\n",
    "final_df['money_per_minute'] = final_df['root_budget']/final_df['runtime']\n",
    "final_df['gross_budget_ratio'] = final_df['usa_gross'] / final_df['budget']\n",
    "final_df['log_gb_ratio'] = np.log(list(final_df['gross_budget_ratio']))\n",
    "final_df['root_gb_ratio'] = np.power(list(final_df['gross_budget_ratio'] + 1), 1/10)\n",
    "final_df['log_gb_diff'] = final_df['log_usa_gross'] - final_df['log_budget']\n",
    "final_df['age_of_star'] = final_df['year'] - final_df['birth_year']\n",
    "\n",
    "# Narrow genres\n",
    "fix_genre_dict = {'Mystery': 'Crime', 'Romance': 'Drama', 'Fantasy': 'Adventure', \n",
    "                  'Sci-Fi': 'Adventure', 'Family': 'Animation', 'Musical': 'Animation'}\n",
    "fixed_genres = []\n",
    "for i in final_df['genres']:\n",
    "    if i in fix_genre_dict:\n",
    "        fixed_genres.append(fix_genre_dict[i])\n",
    "    else:\n",
    "        fixed_genres.append(i)\n",
    "final_df['fixed_genres'] = fixed_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out my variables\n",
    "sorted_var = list(final_df['root_usa_gross'].sort_values(ascending=True))\n",
    "plt.plot(sorted_var);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers to linearize\n",
    "low_cut = final_df['root_usa_gross'].quantile(0.00)\n",
    "high_cut = final_df['root_usa_gross'].quantile(0.98)\n",
    "original_y = final_df['usa_gross']\n",
    "for i, val in enumerate(final_df['root_usa_gross']):\n",
    "    if (val <= low_cut):\n",
    "        final_df.loc[i,'root_usa_gross'] = None\n",
    "    elif (val >= high_cut):\n",
    "        final_df.loc[i,'root_usa_gross'] = None\n",
    "        \n",
    "final_df.dropna(inplace=True)\n",
    "\n",
    "# Drop everything before 1985\n",
    "# final_df.drop(list(final_df[final_df['year'] < 1985].index), axis=0, inplace=True)\n",
    "\n",
    "# Need to reset index after dropping rows otherwise when you merge the HOT encoding, the indexes are different\n",
    "# final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check out my variables post harmonization\n",
    "sorted_var = list(final_df['root_usa_gross'].sort_values(ascending=True))\n",
    "plt.plot(sorted_var);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots to compare y before and after transformation\n",
    "fig, ax = plt.subplots(figsize=(14,7))\n",
    "plt.subplot(1,2,1)\n",
    "ax = sns.distplot(final_df['usa_gross']/1000000, kde=False)\n",
    "ax.set(xlabel='USA Box Office Ticket Sales ($USD Millions)', ylabel='Bin Count')\n",
    "plt.subplot(1,2,2)\n",
    "ax = sns.distplot(final_df['root_usa_gross'], kde=False);\n",
    "ax.set(xlabel='Square Root of the USA Gross', ylabel='Bin Count')\n",
    "plt.savefig(fname='outcome_hist', dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "star_profit = final_df.groupby(by=['star','year']).mean()['root_usa_gross']\n",
    "star_meta = final_df.groupby(by=['star','year']).mean()['meta_rating']\n",
    "director_meta = final_df.groupby(by=['director','year']).mean()['meta_rating']\n",
    "\n",
    "# Previous N year's box office gross of star\n",
    "def get_star_power(star, year, N):\n",
    "    past_bank = star_profit.loc[star].loc[year-N:year-1]\n",
    "    if list(past_bank) == []:\n",
    "        return 100000\n",
    "    else:\n",
    "        return np.mean(past_bank)\n",
    "\n",
    "past_bank_short = []\n",
    "past_bank_long = []\n",
    "for i, val in enumerate(final_df['star']):\n",
    "    past_bank_short.append(get_star_power(val, final_df['year'].iloc[i], 1))\n",
    "    past_bank_long.append(get_star_power(val, final_df['year'].iloc[i], 3))\n",
    "    \n",
    "final_df['past_bank_short'] = past_bank_short\n",
    "final_df['past_bank_long'] = past_bank_long\n",
    "\n",
    "# Mean historical metascore of the director's movies in the past N years\n",
    "def get_critical_acclaim(person, year, N):\n",
    "    try:\n",
    "        acclaim = star_meta.loc[person].loc[year-N:year-1]\n",
    "    except:\n",
    "        acclaim = director_meta.loc[person].loc[year-N:year-1]\n",
    "    if list(acclaim) == []:\n",
    "        return 4.0\n",
    "    else:\n",
    "        return np.mean(acclaim)\n",
    "\n",
    "past_acclaim_star = []\n",
    "for i, val in enumerate(final_df['star']):\n",
    "    past_acclaim_star.append(get_critical_acclaim(val, final_df['year'].iloc[i], 3))\n",
    "\n",
    "past_acclaim_director = []\n",
    "for i, val in enumerate(final_df['director']):\n",
    "    past_acclaim_director.append(get_critical_acclaim(val, final_df['year'].iloc[i], 3))\n",
    "    \n",
    "final_df['past_acclaim_star'] = past_acclaim_star\n",
    "final_df['past_acclaim_director'] = past_acclaim_director\n",
    "\n",
    "# Add some polynomial features\n",
    "poly_list = ['age_of_star', 'meta_rating', 'meta_rating', 'runtime', 'past_bank_short', 'past_bank_long',\n",
    "             'past_acclaim_star', 'past_acclaim_director']\n",
    "for i in poly_list:\n",
    "    final_df[i + '_sqr'] = final_df[i]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is sequel?\n",
    "\n",
    "def remove_str(word, test_str):\n",
    "    test_str = re.sub(r'\\b' + word + r'\\b', '', test_str, flags=re.IGNORECASE)\n",
    "    return test_str\n",
    "\n",
    "def clean_str(remove_list, test_str):\n",
    "    for word in remove_list:\n",
    "        test_str = remove_str(word, test_str)\n",
    "    return test_str\n",
    "\n",
    "def similar(a, b):\n",
    "    try:\n",
    "        return SequenceMatcher(None, a, b).ratio()\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_cousins(movie):\n",
    "    sim_scores = []\n",
    "    movie_titles = []\n",
    "    for i in final_df['clean_title']:\n",
    "        sim_score = similar(movie, i)\n",
    "        if sim_score >= 0.75:\n",
    "            sim_scores.append(similar(movie, i))\n",
    "            movie_titles.append(i)\n",
    "    closest_cousins = pd.DataFrame()\n",
    "    closest_cousins['movie'] = movie_titles\n",
    "    closest_cousins['sim_score'] = sim_scores\n",
    "    return closest_cousins.sort_values(by='sim_score', ascending=False)\n",
    "\n",
    "remove_list = ['the ', 'a ', 'an ', 'american ', 'book ', 'of ', 'and ', 'in ', 'perfect ', 'game ',\n",
    "               'green ', 'blue ', 'yellow ', 'black ', 'brown ',\n",
    "               'death ', 'yes ', 'no '\n",
    "              ]\n",
    "final_df['clean_title'] = [clean_str(remove_list, i) for i in final_df['title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['num_cousins'] = [len(get_cousins(i))-1 for i in final_df['clean_title']]\n",
    "final_df.sort_values(by='num_cousins', ascending=False)[['title','num_cousins']][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Harry Potter num_cousins to 8\n",
    "potter_list = list(final_df[final_df['star']=='Daniel Radcliffe'][1:].index)\n",
    "for i in potter_list:\n",
    "    final_df.loc[i,'num_cousins'] = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary variable where if num_cousins > 1\n",
    "is_franchise = []\n",
    "for i in final_df['num_cousins']:\n",
    "    if i > 0:\n",
    "        is_franchise.append(1)\n",
    "    else:\n",
    "        is_franchise.append(0)\n",
    "        \n",
    "final_df['is_franchise'] = is_franchise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_cols = ['root_usa_gross', 'root_budget', 'num_critics', 'meta_rating', 'runtime', 'year', 'money_per_minute',\n",
    "              'age_of_star', 'past_bank_short', 'past_bank_long',\n",
    "              'past_acclaim_star', 'past_acclaim_director',\n",
    "              'is_franchise',\n",
    "              'age_of_star_sqr', 'meta_rating_sqr', 'runtime_sqr', 'past_bank_short_sqr', \n",
    "              'past_bank_long_sqr', 'past_acclaim_star_sqr', 'past_acclaim_director_sqr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best/Worst Actors (Sum over Career)\n",
    "\n",
    "career_star_profit = star_profit.groupby(by='star').sum().sort_values(ascending=False)[0:30]\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.barplot(x=career_star_profit.values, y=career_star_profit.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "career_star_profit = star_profit.groupby(by='star').mean().sort_values(ascending=False)[-30:]\n",
    "sns.barplot(x=career_star_profit.values, y=career_star_profit.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best/Worst Actors (Mean over Career)\n",
    "\n",
    "star_profit = final_df.groupby(by=['star','year']).mean()['profit']\n",
    "career_star_profit = star_profit.groupby(by='star').mean().sort_values(ascending=False)[0:30]\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.barplot(x=career_star_profit.values, y=career_star_profit.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "career_star_profit = star_profit.groupby(by='star').mean().sort_values(ascending=False)[-30:]\n",
    "sns.barplot(x=career_star_profit.values, y=career_star_profit.index);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_gross = list(final_df['usa_gross'].sort_values(ascending=True))\n",
    "sorted_budget = list(final_df['budget'].sort_values(ascending=True))\n",
    "plt.plot(sorted_gross)\n",
    "plt.plot(sorted_budget);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.qqplot(final_df['root_usa_gross']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My OLD Notes\n",
    "# Log(Box office performance) <- to make this more normally distributed\n",
    "    # = intercept \n",
    "    # + B1*month_of_release + B2*weather + B3*meta_rating + B4*unemployment_rate \n",
    "    # + B5*genre + B6*budget + B7*is_sequel + B8*interaction_term(for whether previous was good)\n",
    "    # + B9*age_of_star + B10*rating_of_movie + B11*past_ROI_of_star + B12*past_critic_of_director\n",
    "    # + B13*decade + B14*oscar_count_star1_star2_director + B15*is_original_screenplay\n",
    "    # + B16*contrarian_genre <- is the genre sparse or frequent lately?\n",
    "    \n",
    "# Maybe the supporting star matters more than the star (cuz he/she is cheaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process categorical variables for regression (I no longer use this; use Patsy instead)\n",
    "\n",
    "def get_label_list(value_counts, enc):\n",
    "    col_sums = np.sum(enc, axis=0)\n",
    "    col_labels = []\n",
    "    for i in col_sums:\n",
    "        counter = 0\n",
    "        for j in value_counts:\n",
    "            if i == j:\n",
    "                col_labels.append(value_counts.index[counter])\n",
    "                break\n",
    "            counter += 1\n",
    "    return col_labels\n",
    "\n",
    "# Genre as a categorical variable\n",
    "values = np.array(final_df['fixed_genres'])\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "integer_encoded = integer_encoded.reshape((-1,1))\n",
    "\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "enc_genre = enc.fit_transform(integer_encoded)\n",
    "genre_labels = get_label_list(final_df['fixed_genres'].value_counts(), enc_genre)\n",
    "\n",
    "enc_genre_df = pd.DataFrame(enc_genre, columns=genre_labels)\n",
    "\n",
    "# Month as a categorical variable\n",
    "values = np.array(final_df['release_month'])\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "integer_encoded = integer_encoded.reshape((-1,1))\n",
    "\n",
    "enc = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "enc_month = enc.fit_transform(integer_encoded)\n",
    "month_labels = get_label_list(final_df['release_month'].value_counts(), enc_month)\n",
    "\n",
    "enc_month_df = pd.DataFrame(enc_month, columns=month_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df = final_df[quant_cols].copy()\n",
    "print(quant_df.shape)\n",
    "#quant_df = pd.DataFrame(quant_df, dtype='float')\n",
    "#print(quant_df.shape)\n",
    "#quant_df = pd.concat([quant_df, enc_genre_df], axis=1)\n",
    "#print(quant_df.shape)\n",
    "#quant_df = pd.concat([quant_df, enc_month_df], axis=1)\n",
    "#print(quant_df.shape)\n",
    "\n",
    "corrs = quant_df.corr()\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(corrs, square=True, cmap=\"Blues\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.scatterplot(x='root_budget', y='root_usa_gross', data=final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_var = list(final_df['root_usa_gross'].sort_values(ascending=True))\n",
    "plt.hist(sorted_var, bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = ['root_budget',\n",
    "          'num_critics', 'meta_rating', 'runtime', 'year', \n",
    "          'age_of_star', 'past_bank_short', 'past_bank_long', 'past_acclaim_star',\n",
    "          'past_acclaim_director', 'is_franchise', 'fixed_genres', 'release_month'\n",
    "         #, 'meta_rating_sqr'\n",
    "         #, 'money_per_minute'\n",
    "         #,'age_of_star_sqr', 'runtime_sqr', 'past_bank_short_sqr', \n",
    "         # 'past_bank_long_sqr', 'past_acclaim_star_sqr', 'past_acclaim_director_sqr'\n",
    "         ]\n",
    "x_str = x_cols[0]\n",
    "for i in x_cols[1:]:\n",
    "    x_str = x_str + ' + ' + i\n",
    "x_str = x_str + ' + is_franchise*fixed_genres + is_franchise*meta_rating + fixed_genres*meta_rating'\n",
    "\n",
    "x_patsy = dmatrix(x_str, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(quant_df[quant_cols], height=1.2, aspect=1.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regr = linear_model.LinearRegression()\n",
    "# x = x_patsy\n",
    "# y = quant_df['root_usa_gross']\n",
    "# regr.fit(x, y)\n",
    "\n",
    "# y_pred = regr.predict(x)\n",
    "\n",
    "# # The coefficients\n",
    "# print('Intecept: \\n', regr.intercept_)\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "# print(\"Mean squared error: %.3f\"\n",
    "#       % mean_squared_error(y, y_pred))\n",
    "# print('R^2: %.3f' % r2_score(y, y_pred))\n",
    "\n",
    "# n = y.shape[0]\n",
    "# p = len(x_cols)\n",
    "# adj_r2 = 1 - (1 - r2_score(y, y_pred)) * (n - 1)/(n - p - 1)\n",
    "\n",
    "# print('Adjusted R^2: %.3f' % adj_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_df = pd.DataFrame()\n",
    "# error_df['y'] = y\n",
    "# error_df['y_pred'] = y_pred\n",
    "# error_df['resid'] = y - y_pred\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8,8))\n",
    "# sns.scatterplot(x='y_pred', y='y', data=error_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(8,8))\n",
    "# sns.scatterplot(x='y_pred', y='resid', data=error_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Stats Model Code\n",
    "\n",
    "# x_const = sm.add_constant(x_train, prepend=True)\n",
    "# model = smf.ols(formula='log_gb_ratio ~ ' + x_str, data = final_df)\n",
    "# fitted_model = model.fit()\n",
    "\n",
    "# print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_df_2 = quant_df.copy()\n",
    "\n",
    "x_raw = x_patsy\n",
    "y_raw = quant_df_2.loc[:, quant_df_2.columns == 'root_usa_gross']\n",
    "y_raw = y_raw.values.reshape((-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_raw, y_raw, test_size=0.2, random_state=0)\n",
    "\n",
    "regr_2 = linear_model.LinearRegression()\n",
    "regr_2.fit(x_train, y_train)\n",
    "scores = cross_val_score(regr_2, x_train, y_train, cv=7, scoring='r2')\n",
    "print(scores)\n",
    "print('Out of Sample R^2: %.3f' % np.mean(scores))\n",
    "print('In Sample R^2:     %.3f' % r2_score(y_train, regr_2.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize my variables for ridge regression\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_norm = scaler.transform(x_train)\n",
    "x_norm_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid search to find the optimal lambda for a Ridge Regression\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10, 15, 20, 25, 30, 50, 100, 500, 1000]\n",
    "#alphas = [i for i in range(100,300)]\n",
    "param_grid = [{'alpha': alphas}]\n",
    "ridge = GridSearchCV(Ridge(alpha=10), param_grid, cv=7, scoring='r2', return_train_score=True)\n",
    "ridge.fit(x_norm, y_train)\n",
    "y_ridge = ridge.predict(x_norm)\n",
    "\n",
    "ridge_base = Ridge(alpha=0.01)\n",
    "ridge_base.fit(x_norm, y_train)\n",
    "\n",
    "ridge_best = Ridge(alpha=ridge.best_params_['alpha'])\n",
    "ridge_best.fit(x_norm, y_train)\n",
    "\n",
    "print(ridge.best_params_)\n",
    "print(ridge.best_score_)\n",
    "\n",
    "plt.plot(ridge.best_estimator_.coef_[0])\n",
    "plt.plot(ridge_base.coef_[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid search to find the optimal lambda for a Lasso Regression\n",
    "\n",
    "alphas = [0.01, 0.1, 1, 10, 50, 100, 500, 1000]\n",
    "param_grid = [{'alpha': alphas}]\n",
    "lasso = GridSearchCV(Lasso(alpha=10), param_grid, cv=7, scoring='r2', return_train_score=True)\n",
    "lasso.fit(x_norm, y_train)\n",
    "y_lasso = lasso.predict(x_norm)\n",
    "\n",
    "lasso_base = Lasso(alpha=0.01)\n",
    "lasso_base.fit(x_norm, y_train)\n",
    "\n",
    "lasso_best = Lasso(alpha=lasso.best_params_['alpha'])\n",
    "lasso_best.fit(x_norm, y_train)\n",
    "\n",
    "print(lasso.best_params_)\n",
    "print(lasso.best_score_)\n",
    "\n",
    "plt.plot(lasso.best_estimator_.coef_)\n",
    "plt.plot(lasso_base.coef_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid search to find the optimal lambda and l1_ratio for an Elastic Net Regression\n",
    "\n",
    "alphas = [i for i in [0.01, 0.1, 1, 10, 50, 100, 500, 1000]]\n",
    "l1_ratios = [i/100 for i in range(1,101)]\n",
    "param_grid = [{'alpha': alphas, 'l1_ratio': l1_ratios}]\n",
    "elastic = GridSearchCV(ElasticNet(alpha=1, l1_ratio=0.5), param_grid, cv=7, scoring='r2', return_train_score=True)\n",
    "elastic.fit(x_norm, y_train)\n",
    "y_elastic = elastic.predict(x_norm)\n",
    "\n",
    "print(elastic.best_params_)\n",
    "print(elastic.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coef_dict(dmat, model):\n",
    "    coef_dict = {}\n",
    "    names = dmat.design_info.column_names\n",
    "    #coefs = model.coef_[0]\n",
    "    coefs = model.coef_\n",
    "    for i, val in enumerate(names):\n",
    "        if i == 0:\n",
    "            coef_dict[val] = model.intercept_[0]\n",
    "        else:\n",
    "            coef_dict[val] = coefs[i]\n",
    "    return coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lasso_best\n",
    "\n",
    "coef_dict = get_coef_dict(x_patsy, best_model)\n",
    "coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in and out of sample R^2\n",
    "y_train_pred = best_model.predict(x_norm)\n",
    "y_test_pred = best_model.predict(x_norm_test)\n",
    "\n",
    "error_df_test = pd.DataFrame()\n",
    "error_df_test['y'] = [i[0] for i in y_test]\n",
    "error_df_test['y_pred'] = [i for i in y_test_pred]\n",
    "error_df_test['resid'] = error_df_test['y'] - error_df_test['y_pred']\n",
    "sns.scatterplot(x='y_pred', y='y', data=error_df_test);\n",
    "plt.show()\n",
    "\n",
    "error_df_train = pd.DataFrame()\n",
    "error_df_train['y'] = [i[0] for i in y_train]\n",
    "error_df_train['y_pred'] = [i for i in y_train_pred]\n",
    "error_df_train['resid'] = error_df_train['y'] - error_df_train['y_pred']\n",
    "sns.scatterplot(x='y_pred', y='y', data=error_df_train, color='orange');\n",
    "\n",
    "mse_test = sum(np.square(error_df_test['resid']))/error_df_test.shape[0]\n",
    "mse_train = sum(np.square(error_df_train['resid']))/error_df_train.shape[0]\n",
    "\n",
    "rmse_test = np.power(mse_test, 1/2)**2\n",
    "rmse_train = np.power(mse_train, 1/2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('In Sample R^2: %.3f' % r2_score(y_train, y_train_pred))\n",
    "print('Out of Sample R^2: %.3f' % r2_score(y_test, y_test_pred))\n",
    "print('\\n')\n",
    "print('In Sample RMSE: %.3f' % rmse_train)\n",
    "print('Out of Sample RMSE: %.3f' % rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.scatterplot(x='y_pred', y='resid', data=error_df_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "sns.scatterplot(x='y_pred', y='resid', data=error_df_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(error_df_train['resid'], dist='norm', plot=plt)\n",
    "plt.title('Normal QQ Plot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.probplot(error_df_test['resid'], dist='norm', plot=plt)\n",
    "plt.title('Normal QQ Plot');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(error_df_train['resid'], 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some interesting stats\n",
    "mean_budget = np.mean(final_df['budget'])\n",
    "sum([1 for i in final_df['profit'] if i<mean_budget*0.03])/final_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sort_values(by='profit')[['title','profit']][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out my p-values\n",
    "\n",
    "model = smf.ols(formula='root_usa_gross ~ ' + x_str, data = final_df)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
